import sys
import os
import pandas as pd
import uuid
import re
from datetime import datetime
from dotenv import load_dotenv

# Add current directory to path
sys.path.append(os.getcwd())
load_dotenv()

from database.mongo_handler import get_mongodb_handler

def parse_date(date_str):
    """ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if pd.isna(date_str) or not date_str:
        return None

    date_str = str(date_str).strip()

    # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
    if '~' in date_str:
        # ë²”ìœ„ê°€ ìˆëŠ” ê²½ìš° ì¢…ë£Œì¼ë§Œ ì‚¬ìš©
        date_str = date_str.split('~')[-1].strip()

    # YYYYMMDD í˜•ì‹ ì²˜ë¦¬
    if len(date_str) == 8 and date_str.isdigit():
        try:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        except:
            return None

    # ê¸°íƒ€ í˜•ì‹ì€ ìƒì‹œë¡œ ì²˜ë¦¬
    return "ìƒì‹œ"

def extract_age_from_conditions(conditions_text):
    """ì¡°ê±´ í…ìŠ¤íŠ¸ì—ì„œ ë‚˜ì´ ì •ë³´ ì¶”ì¶œ"""
    if pd.isna(conditions_text):
        return None, None

    text = str(conditions_text)

    # ë‚˜ì´ ê´€ë ¨ íŒ¨í„´ ì°¾ê¸°
    age_patterns = [
        r'(\d+)ì„¸?\s*~\s*(\d+)ì„¸',
        r'(\d+)ì„¸?\s*ì´ìƒ\s*(\d+)ì„¸?\s*ì´í•˜',
        r'ë§Œ\s*(\d+)ì„¸?\s*~\s*ë§Œ?\s*(\d+)ì„¸',
    ]

    for pattern in age_patterns:
        match = re.search(pattern, text)
        if match:
            return int(match.group(1)), int(match.group(2))

    # ë‹¨ì¼ ë‚˜ì´ íŒ¨í„´
    single_age_patterns = [
        r'(\d+)ì„¸?\s*ì´í•˜',
        r'(\d+)ì„¸?\s*ë¯¸ë§Œ'
    ]

    for pattern in single_age_patterns:
        match = re.search(pattern, text)
        if match:
            return 18, int(match.group(1))  # ê¸°ë³¸ ìµœì†Œ ë‚˜ì´ 18ì„¸

    return None, None

def extract_region_from_name(policy_name, org_name):
    """ì •ì±…ëª…ê³¼ ê¸°ê´€ëª…ì—ì„œ ì§€ì—­ ì¶”ì¶œ"""
    # ê´‘ì—­ì‹œ/ë„
    major_regions = ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
                    'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼']

    # ì‹œ/êµ°/êµ¬ (ë” ë§ì€ ì§€ì—­ ì¶”ê°€)
    minor_regions = [
        # ê²½ê¸°ë„
        'ìˆ˜ì›', 'ì„±ë‚¨', 'ìš©ì¸', 'ì•ˆì–‘', 'ì•ˆì‚°', 'ê³ ì–‘', 'ê³¼ì²œ', 'êµ¬ë¦¬', 'ë‚¨ì–‘ì£¼', 'ì˜¤ì‚°',
        'ì‹œí¥', 'êµ°í¬', 'ì˜ì™•', 'í•˜ë‚¨', 'ì–‘ì£¼', 'ë™ë‘ì²œ', 'ì˜ì •ë¶€', 'íŒŒì£¼', 'ì´ì²œ',
        'ì•ˆì„±', 'ê¹€í¬', 'í™”ì„±', 'ê´‘ì£¼ì‹œ', 'ì—¬ì£¼', 'ì—°ì²œ', 'ê°€í‰', 'ì–‘í‰',
        # ì „ë¼ë¶ë„
        'ì „ì£¼', 'êµ°ì‚°', 'ìµì‚°', 'ì •ì', 'ë‚¨ì›', 'ê¹€ì œ', 'ì™„ì£¼', 'ì§„ì•ˆ', 'ë¬´ì£¼', 'ì¥ìˆ˜',
        'ì„ì‹¤', 'ìˆœì°½', 'ê³ ì°½', 'ë¶€ì•ˆ',
        # ì „ë¼ë‚¨ë„
        'ëª©í¬', 'ì—¬ìˆ˜', 'ìˆœì²œ', 'ë‚˜ì£¼', 'ê´‘ì–‘', 'ë‹´ì–‘', 'ê³¡ì„±', 'êµ¬ë¡€', 'ê³ í¥', 'ë³´ì„±',
        'í™”ìˆœ', 'ì¥í¥', 'ê°•ì§„', 'í•´ë‚¨', 'ì˜ì•”', 'ë¬´ì•ˆ', 'í•¨í‰', 'ì˜ê´‘', 'ì¥ì„±', 'ì™„ë„', 'ì§„ë„',
        # ê²½ìƒë‚¨ë„
        'ì°½ì›', 'ì§„ì£¼', 'í†µì˜', 'ì‚¬ì²œ', 'ê¹€í•´', 'ë°€ì–‘', 'ê±°ì œ', 'ì–‘ì‚°', 'ì˜ë ¹', 'í•¨ì•ˆ',
        'ì°½ë…•', 'ê³ ì„±', 'ë‚¨í•´', 'í•˜ë™', 'ì‚°ì²­', 'í•¨ì–‘', 'ê±°ì°½', 'í•©ì²œ',
        # ê²½ìƒë¶ë„
        'í¬í•­', 'ê²½ì£¼', 'ê¹€ì²œ', 'ì•ˆë™', 'êµ¬ë¯¸', 'ì˜ì£¼', 'ì˜ì²œ', 'ìƒì£¼', 'ë¬¸ê²½', 'ê²½ì‚°',
        # ì¶©ì²­ë‚¨ë„
        'ì²œì•ˆ', 'ê³µì£¼', 'ë³´ë ¹', 'ì•„ì‚°', 'ì„œì‚°', 'ë…¼ì‚°', 'ê³„ë£¡', 'ë‹¹ì§„', 'ê¸ˆì‚°', 'ë¶€ì—¬',
        'ì„œì²œ', 'ì²­ì–‘', 'í™ì„±', 'ì˜ˆì‚°', 'íƒœì•ˆ',
        # ì¶©ì²­ë¶ë„
        'ì²­ì£¼', 'ì¶©ì£¼', 'ì œì²œ', 'ë³´ì€', 'ì˜¥ì²œ', 'ì˜ë™', 'ì¦í‰', 'ì§„ì²œ', 'ê´´ì‚°', 'ìŒì„±', 'ë‹¨ì–‘',
        # ê°•ì›ë„
        'ì¶˜ì²œ', 'ì›ì£¼', 'ê°•ë¦‰', 'ë™í•´', 'íƒœë°±', 'ì†ì´ˆ', 'ì‚¼ì²™', 'í™ì²œ', 'íš¡ì„±', 'ì˜ì›”',
        'í‰ì°½', 'ì •ì„ ', 'ì² ì›', 'í™”ì²œ', 'ì–‘êµ¬', 'ì¸ì œ', 'ê³ ì„±', 'ì–‘ì–‘',
        # ì œì£¼ë„
        'ì œì£¼ì‹œ', 'ì„œê·€í¬'
    ]

    text = f"{policy_name} {org_name}".lower()

    # ì‹œ/êµ°/êµ¬ ë¨¼ì € í™•ì¸ (ë” êµ¬ì²´ì ì´ë¯€ë¡œ)
    for region in minor_regions:
        if region.lower() in text:
            # ì‹œ/êµ°/êµ¬ë¥¼ ê´‘ì—­ì‹œ/ë„ë¡œ ë§¤í•‘
            region_map = {
                # ê²½ê¸°ë„
                'ìˆ˜ì›': 'ê²½ê¸°', 'ì„±ë‚¨': 'ê²½ê¸°', 'ìš©ì¸': 'ê²½ê¸°', 'ì•ˆì–‘': 'ê²½ê¸°',
                'ì•ˆì‚°': 'ê²½ê¸°', 'ê³ ì–‘': 'ê²½ê¸°', 'ê³¼ì²œ': 'ê²½ê¸°', 'êµ¬ë¦¬': 'ê²½ê¸°',
                'ë‚¨ì–‘ì£¼': 'ê²½ê¸°', 'ì˜¤ì‚°': 'ê²½ê¸°', 'ì‹œí¥': 'ê²½ê¸°', 'êµ°í¬': 'ê²½ê¸°',
                'ì˜ì™•': 'ê²½ê¸°', 'í•˜ë‚¨': 'ê²½ê¸°', 'ì–‘ì£¼': 'ê²½ê¸°', 'ë™ë‘ì²œ': 'ê²½ê¸°',
                'ì˜ì •ë¶€': 'ê²½ê¸°', 'íŒŒì£¼': 'ê²½ê¸°', 'ì´ì²œ': 'ê²½ê¸°', 'ì•ˆì„±': 'ê²½ê¸°',
                'ê¹€í¬': 'ê²½ê¸°', 'í™”ì„±': 'ê²½ê¸°', 'ì—¬ì£¼': 'ê²½ê¸°', 'ì—°ì²œ': 'ê²½ê¸°',
                'ê°€í‰': 'ê²½ê¸°', 'ì–‘í‰': 'ê²½ê¸°',
                # ì „ë¼ë¶ë„
                'ì „ì£¼': 'ì „ë¶', 'êµ°ì‚°': 'ì „ë¶', 'ìµì‚°': 'ì „ë¶', 'ì •ì': 'ì „ë¶',
                'ë‚¨ì›': 'ì „ë¶', 'ê¹€ì œ': 'ì „ë¶', 'ì™„ì£¼': 'ì „ë¶', 'ì§„ì•ˆ': 'ì „ë¶',
                'ë¬´ì£¼': 'ì „ë¶', 'ì¥ìˆ˜': 'ì „ë¶', 'ì„ì‹¤': 'ì „ë¶', 'ìˆœì°½': 'ì „ë¶',
                'ê³ ì°½': 'ì „ë¶', 'ë¶€ì•ˆ': 'ì „ë¶',
                # ì „ë¼ë‚¨ë„
                'ëª©í¬': 'ì „ë‚¨', 'ì—¬ìˆ˜': 'ì „ë‚¨', 'ìˆœì²œ': 'ì „ë‚¨', 'ë‚˜ì£¼': 'ì „ë‚¨',
                'ê´‘ì–‘': 'ì „ë‚¨', 'ë‹´ì–‘': 'ì „ë‚¨', 'ê³¡ì„±': 'ì „ë‚¨', 'êµ¬ë¡€': 'ì „ë‚¨',
                # ê²½ìƒë‚¨ë„
                'ì°½ì›': 'ê²½ë‚¨', 'ì§„ì£¼': 'ê²½ë‚¨', 'í†µì˜': 'ê²½ë‚¨', 'ì‚¬ì²œ': 'ê²½ë‚¨',
                'ê¹€í•´': 'ê²½ë‚¨', 'ë°€ì–‘': 'ê²½ë‚¨', 'ê±°ì œ': 'ê²½ë‚¨', 'ì–‘ì‚°': 'ê²½ë‚¨',
                # ê¸°íƒ€ ì§€ì—­ë“¤...
            }
            mapped_region = region_map.get(region, region)
            return [mapped_region]

    # ê´‘ì—­ì‹œ/ë„ í™•ì¸
    for region in major_regions:
        if region.lower() in text:
            return [region]

    return ['ì „êµ­']

def categorize_policy(major_cat, minor_cat, policy_name):
    """ì •ì±…ì„ ìš°ë¦¬ ì‹œìŠ¤í…œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
    text = f"{major_cat} {minor_cat} {policy_name}".lower()

    # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    if any(word in text for word in ['ì¼ìë¦¬', 'ì·¨ì—…', 'ê³ ìš©', 'êµ¬ì§', 'ì±„ìš©', 'ì§ì—…', 'ì¸í„´', 'ì§ì¥']):
        return 'ì¼ìë¦¬'
    elif any(word in text for word in ['ì£¼ê±°', 'ì£¼íƒ', 'ì „ì„¸', 'ì›”ì„¸', 'ì„ëŒ€', 'ê±°ì£¼']):
        return 'ì£¼ê±°'
    elif any(word in text for word in ['ì°½ì—…', 'ì‚¬ì—…', 'ê¸°ì—…', 'ìŠ¤íƒ€íŠ¸ì—…', 'ë²¤ì²˜']):
        return 'ì°½ì—…'
    elif any(word in text for word in ['ê¸ˆìœµ', 'ëŒ€ì¶œ', 'ì ê¸ˆ', 'ë³´í—˜', 'íˆ¬ì', 'ìê¸ˆ']):
        return 'ê¸ˆìœµ'
    elif any(word in text for word in ['êµìœ¡', 'í•™ìŠµ', 'ì—°ìˆ˜', 'ê°•ì˜', 'í›ˆë ¨', 'í•™êµ']):
        return 'êµìœ¡'
    elif any(word in text for word in ['ë³µì§€', 'ì§€ì›', 'ë³´ì¡°', 'ê±´ê°•', 'ì˜ë£Œ', 'ìƒë‹´']):
        return 'ë³µì§€'
    elif any(word in text for word in ['ë¬¸í™”', 'ì˜ˆìˆ ', 'ì²´í—˜', 'ì—¬í–‰', 'ê´€ê´‘']):
        return 'ë¬¸í™”'
    else:
        return 'ë³µì§€'  # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬

def extract_employment_target(conditions_text, policy_name):
    """ê³ ìš© ëŒ€ìƒ ì¶”ì¶œ"""
    if pd.isna(conditions_text):
        conditions_text = ""

    text = f"{conditions_text} {policy_name}".lower()

    targets = []
    if any(word in text for word in ['êµ¬ì§', 'ë¯¸ì·¨ì—…', 'ë¬´ì§', 'ì‹¤ì—…']):
        targets.append('êµ¬ì§ì')
    if any(word in text for word in ['ì¬ì§', 'ê·¼ë¡œ', 'ì§ì¥', 'íšŒì‚¬ì›']):
        targets.append('ì¬ì§ì')
    if any(word in text for word in ['í•™ìƒ', 'ëŒ€í•™ìƒ', 'ì¬í•™']):
        targets.append('í•™ìƒ')
    if any(word in text for word in ['ìì˜ì—…', 'ì‚¬ì—…ì', 'í”„ë¦¬ëœì„œ']):
        targets.append('ìì˜ì—…')

    # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ëª¨ë“  ëŒ€ìƒ
    if not targets:
        targets = ['êµ¬ì§ì', 'ì¬ì§ì', 'í•™ìƒ', 'ìì˜ì—…']

    return targets

def extract_income_limit(conditions_text, benefit_text):
    """ì†Œë“ ì œí•œ ì¶”ì¶œ (ë§Œì› ë‹¨ìœ„)"""
    if pd.isna(conditions_text):
        conditions_text = ""
    if pd.isna(benefit_text):
        benefit_text = ""

    text = f"{conditions_text} {benefit_text}".lower()

    # ì†Œë“ ì œí•œ íŒ¨í„´ ì°¾ê¸°
    income_patterns = [
        r'ì†Œë“\s*(\d+)ë§Œì›\s*ì´í•˜',
        r'ì—°ì†Œë“\s*(\d+)ë§Œì›\s*ì´í•˜',
        r'ì¤‘ìœ„ì†Œë“\s*(\d+)%\s*ì´í•˜',
        r'(\d+)ë§Œì›\s*ì´í•˜'
    ]

    for pattern in income_patterns:
        match = re.search(pattern, text)
        if match:
            amount = int(match.group(1))
            if 'ì¤‘ìœ„ì†Œë“' in match.group(0):
                # ì¤‘ìœ„ì†Œë“ ê¸°ì¤€ì„ ëŒ€ëµì ì¸ ê¸ˆì•¡ìœ¼ë¡œ ë³€í™˜
                return amount * 50  # ì¤‘ìœ„ì†Œë“ 100% = ì•½ 5000ë§Œì› ê¸°ì¤€
            return amount

    return None  # ì†Œë“ ì œí•œ ì—†ìŒ

def load_real_policies():
    """ì‹¤ì œ ì •ì±… ë°ì´í„°ë¥¼ CSVì—ì„œ ë¡œë“œí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    print("ğŸŒ± ì‹¤ì œ ì •ì±… ë°ì´í„°(CSV)ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œë“œ ì‹œì‘...")

    # MongoDB ì—°ê²°
    handler = get_mongodb_handler()
    if not handler or not handler.is_connected:
        print("âŒ Database not connected")
        return False

    # CSV ë¡œë“œ
    try:
        df = pd.read_csv('data/policies_raw.csv')
        print(f"ğŸ“„ CSVì—ì„œ {len(df)}ê°œ ì •ì±… ë°ì´í„° ë¡œë“œ")
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    # ê¸°ì¡´ ì •ì±… ì‚­ì œ
    policies_collection = handler.database["policies"]
    policies_collection.delete_many({})
    print("ğŸ—‘ï¸ ê¸°ì¡´ ì •ì±… ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

    # ì •ì±… ë³€í™˜ ë° ì €ì¥
    converted_policies = []
    success_count = 0

    for idx, row in df.iterrows():
        try:
            # ê¸°ë³¸ ì •ë³´
            policy_name = str(row['plcyNm']).strip()
            if not policy_name or policy_name == 'nan':
                continue

            policy_desc = str(row.get('plcyExplnCn', '')).strip()
            major_cat = str(row.get('mclsfNm', '')).strip()
            minor_cat = str(row.get('lclsfNm', '')).strip()
            conditions = str(row.get('addAplyQlfcCndCn', '')).strip()
            org_name = str(row.get('operInstCdNm', '')).strip()

            # ë‚˜ì´ ì¡°ê±´ ì¶”ì¶œ
            csv_min_age = row.get('sprtTrgtMinAge', 0)
            csv_max_age = row.get('sprtTrgtMaxAge', 0)

            # CSVì˜ ë‚˜ì´ê°€ 0ì´ë©´ ì¡°ê±´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            if csv_min_age == 0 or csv_max_age == 0:
                extracted_min, extracted_max = extract_age_from_conditions(conditions)
                target_age_min = extracted_min if extracted_min else (csv_min_age if csv_min_age > 0 else 18)
                target_age_max = extracted_max if extracted_max else (csv_max_age if csv_max_age > 0 else 39)
            else:
                target_age_min = int(csv_min_age)
                target_age_max = int(csv_max_age)

            # 39ì„¸ ì´ˆê³¼ëŠ” 39ì„¸ë¡œ ì œí•œ (ì²­ë…„ ì •ì±…)
            if target_age_max > 39:
                target_age_max = 39
            if target_age_min < 18:
                target_age_min = 18

            # ë§ˆê°ì¼ ì²˜ë¦¬
            end_date = parse_date(row.get('bizPrdEndYmd'))
            if not end_date:
                end_date = "ìƒì‹œ"

            # ì •ì±… ë°ì´í„° ìƒì„±
            policy_data = {
                "policy_id": f"REAL_{idx+1:04d}",
                "title": policy_name,
                "category": categorize_policy(major_cat, minor_cat, policy_name),
                "target_age_min": target_age_min,
                "target_age_max": target_age_max,
                "target_regions": extract_region_from_name(policy_name, org_name),
                "target_employment": extract_employment_target(conditions, policy_name),
                "target_income_max": extract_income_limit(conditions, policy_desc),
                "benefit": policy_desc[:200] + "..." if len(policy_desc) > 200 else policy_desc,
                "budget_max": None,  # CSVì—ì„œ ì¶”ì¶œí•˜ê¸° ì–´ë ¤ì›€
                "deadline": end_date,
                "application_url": str(row.get('aplyUrlAddr', '')).strip() or None,
                "agency": org_name or "ë¯¸ìƒ",
                "is_active": True,
                "requirements": [conditions[:100]] if conditions and conditions != 'nan' else [],
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }

            converted_policies.append(policy_data)
            success_count += 1

            # ì§„í–‰ ìƒí™© ì¶œë ¥ (100ê°œë§ˆë‹¤)
            if success_count % 100 == 0:
                print(f"   ì²˜ë¦¬ë¨: {success_count}ê°œ...")

        except Exception as e:
            print(f"âš ï¸ ì •ì±… {idx+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

    # ë°ì´í„°ë² ì´ìŠ¤ì— ì¼ê´„ ì €ì¥
    if converted_policies:
        try:
            result = policies_collection.insert_many(converted_policies)
            print(f"âœ… {len(result.inserted_ids)}ê°œ ì •ì±… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")

            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            categories = {}
            for policy in converted_policies:
                cat = policy['category']
                categories[cat] = categories.get(cat, 0) + 1

            print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì •ì±… ìˆ˜:")
            for cat, count in sorted(categories.items()):
                print(f"   - {cat}: {count}ê°œ")

            return True

        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    else:
        print("âŒ ë³€í™˜ëœ ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤")
        return False

if __name__ == "__main__":
    success = load_real_policies()
    if success:
        print("\nğŸ‰ ì‹¤ì œ ì •ì±… ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
    else:
        print("\nâŒ ì •ì±… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")